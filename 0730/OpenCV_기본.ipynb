{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Open CV\r\n",
    "- OpenCV(Open Source Computer Vision)은 오픈소스 컴퓨터 비전 라이브러리\r\n",
    "- OpenCV는 단일 이미지나 동영상의 이미지를 원하는 결과를 분석 및 추출하기위한 API\r\n",
    "- 객체, 얼굴, 행동, 인식, 독순, 모션 추척 등의 응용 프로그램에서 사용\r\n",
    "- 사이트: https://docs.opencv.org/4.2.0/d1/dfb/intro.html\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import cv2\r\n",
    "cv2.__version__"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'4.5.3'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "cap_img=cv2.VideoCapture(0) # 사용중인 PC에 연결된 웹캠 또는 카메라 영상 연결\r\n",
    "cap_img.set(cv2.CAP_PROP_FRAME_WIDTH, 640) # capture.set(option, n) 카메라의 속성을 설정\r\n",
    "cap_img.set(cv2.CAP_PROP_FRAME_HEIGHT, 480) # option : 프레임의 너비와 높이등의 속성을 설정\r\n",
    "\r\n",
    "# 영상 출력을 위한 캡쳐 반복\r\n",
    "while True:\r\n",
    "    ret, frame = cap_img.read()      # 카메라의 상태 및 프레임, ret은 카메라 상태 저장(정상 작동 True, 미작동 False)\r\n",
    "    cv2.imshow('VideoFrame', frame) # cv2.imshow('윈도우 창 제목', 이미지)\r\n",
    "    if cv2.waitKey(1)>0:break       # 키보드의 아무키나 누르면 종료\r\n",
    "\r\n",
    "cap_img.release                     # 카메라 장치에서 받아온 메모리 해제\r\n",
    "cv2.destroyAllWindows               # cv2.destroyWindow('윈도우 창 제목'): 특정 윈도우 창만 닫을 수 있다."
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<function destroyAllWindows>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 카메라 영상을 파일로 저장"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "\r\n",
    "cap=cv2.VideoCapture(0)\r\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # XVID 코덱 사용(XVID 는 mp4 또는 avi등을 지원, 코덱이 지원하는 확장자 사용해야함)\r\n",
    "out_cap=cv2.VideoWriter('c:/pythonworkspace/multi/0730/data/out_video_1.mp4', fourcc, 20.0, (640, 480))\r\n",
    "# 파일명, 프레임(20.0), 영상크기(640, 480) 지정\r\n",
    "\r\n",
    "while cap.isOpened():\r\n",
    "    ret, frame = cap.read()\r\n",
    "    if ret == True:\r\n",
    "        frame = cv2.flip(frame, 0) # 1은 좌우반전, 0은 상하반전\r\n",
    "        out_cap.write(frame)\r\n",
    "\r\n",
    "        cv2.imshow('Save_Frame', frame)\r\n",
    "        if cv2.waitKey(1)>0:break\r\n",
    "    else:\r\n",
    "        break\r\n",
    "\r\n",
    "cap.release()               # 캠 종료\r\n",
    "out_cap.release()           # 저장 종료\r\n",
    "cv2.destroyAllWindows()     # 창 종료\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 저장된 동영상 파일 화면에서 표시"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "cap = cv2.VideoCapture('c:/pythonworkspace/multi/Bee.mp4')\r\n",
    "\r\n",
    "while True:\r\n",
    "    # 현재 프레임의 위치가 전체 프레임과 같으면 다시 영상 읽어오기\r\n",
    "    if (cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT)):\r\n",
    "        cap.open('c:/pythonworkspace/multi/Bee.mp4')\r\n",
    "\r\n",
    "\r\n",
    "    ret, frame = cap.read()\r\n",
    "    cv2.imshow('Bee_video', frame)\r\n",
    "\r\n",
    "    if cv2.waitKey(33) > 0: break # 33ms마다 프레임 재생, 아무키나 누르면 종료\r\n",
    "\r\n",
    "cap.release()               # 캠 종료\r\n",
    "cv2.destroyAllWindows()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import datetime\r\n",
    "import cv2\r\n",
    "\r\n",
    "cap = cv2.VideoCapture('c:/pythonworkspace/multi/blackpink.mp4')\r\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID') # XVID코덱, 디지털 미디어 포맷 코드\r\n",
    "record = False # 녹화 유무 설정\r\n",
    "\r\n",
    "while True:\r\n",
    "    if (cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT)):\r\n",
    "        cap.open('c:/pythonworkspace/multi/blackpink.mp4')\r\n",
    "\r\n",
    "    ret, frame = cap.read()\r\n",
    "    cv2.imshow('blackpink', frame)\r\n",
    "\r\n",
    "    now = datetime.datetime.now().strftime(\"%d_%H-%M-%S\") # 현재 시간을 받아와 제목으로 사용\r\n",
    "    key = cv2.waitKey(24) # 33s마다 갱신 \r\n",
    "\r\n",
    "    # - 키값별 숫자: ESC(27), Ctrl+Z(26), Ctrl+X(24), Ctrl+R(18)\r\n",
    "    if key == 27:\r\n",
    "        break\r\n",
    "    elif key==26:\r\n",
    "        print('캡쳐합니다.')\r\n",
    "        cv2.imwrite('c:/pythonworkspace/multi/'+str(now)+'.png', frame)\r\n",
    "        print('캡쳐완료')\r\n",
    "    elif key == 18:\r\n",
    "        print('녹화 시작')\r\n",
    "        record = True\r\n",
    "        video = cv2.VideoWriter('c:/pythonworkspace/multi/'+str(now)+'.avi', fourcc, 20.0, (frame.shape[1], frame[0]))\r\n",
    "        # (경로및 제목, 비디오 포맷 코드, FPS, (녹화파일너비, 녹화파일 높이))\r\n",
    "    elif key == 24:\r\n",
    "        print('녹화 중지')\r\n",
    "        record=False\r\n",
    "        video.release()\r\n",
    "\r\n",
    "    if record == True:\r\n",
    "        # print('녹화 중..')\r\n",
    "        video.write(frame)\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "녹화 중지\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'video' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29124/3703188283.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'녹화 중지'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mrecord\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mvideo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mrecord\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 웹캠에서 사람 얼굴 인지하기\r\n",
    "- 참고 : https://github.com/opencv/opencv/tree/master/data/haarcascades"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\r\n",
    "import cv2\r\n",
    "\r\n",
    "face_case = cv2.CascadeClassifier('c:/pythonworkspace/multi/0730/data/haarcascade_frontalface_default.xml')\r\n",
    "\r\n",
    "cap = cv2.VideoCapture(0)\r\n",
    "cap.set(3, 640)\r\n",
    "cap.set(4, 480)\r\n",
    "\r\n",
    "while True:\r\n",
    "\r\n",
    "    ret, frame = cap.read()\r\n",
    "    frame = cv2.flip(frame, 1) # 좌우대칭\r\n",
    "    faces = face_case.detectMultiScale(frame, 1.05, 5)\r\n",
    "\r\n",
    "    if len(faces):\r\n",
    "        for (x, y, w, h) in faces:\r\n",
    "            cv2.rectangle(frame, (x,y), (x+w, y+h), (255, 0, 0), 2)\r\n",
    "\r\n",
    "    cv2.imshow('faces', frame)\r\n",
    "    if cv2.waitKey(24) ==27 : break # ESC입력시 종료\r\n",
    "\r\n",
    "cap.release()\r\n",
    "cv2.destroyAllWindows\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# 예지님 코드\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import cv2\r\n",
    "\r\n",
    "face_case = cv2.CascadeClassifier('c:/pydata/haarcascade_frontalface_default.xml')\r\n",
    "\r\n",
    "cap=cv2.VideoCapture(0) # 사용중인 PC에 연결된 웹캠 또는 카메라 영상 연결\r\n",
    "cap.set(3, 640)  # 너비\r\n",
    "cap.set(4, 480)   # 높이\r\n",
    "\r\n",
    "while True: \r\n",
    "    ret, frame = cap.read() \r\n",
    "    frame = cv2.flip(frame,1) # 좌우대칭\r\n",
    "    faces = face_case.detectMultiScale(frame, 1.05, 5)\r\n",
    "\r\n",
    "    if len(faces):\r\n",
    "        for (x,y,w,h) in faces:\r\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h),(255,0,0),2)\r\n",
    "\r\n",
    "\r\n",
    "    cv2.imshow('faces',frame) # cv2.imshow(\"윈도우 창 제목\", 이미지)\r\n",
    "    if cv2.waitKey(24) == 27 : break # esc  키 입력시 종료 \r\n",
    "\r\n",
    "\r\n",
    "cap.release()              # 카메라 장치에서 받아온 메모리 해제\r\n",
    "cv2.destroyAllWindows()\r\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5340/2311954367.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'faces'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# cv2.imshow(\"윈도우 창 제목\", 이미지)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m24\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;32mbreak\u001b[0m \u001b[1;31m# esc  키 입력시 종료\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-q3d_8t8e\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}